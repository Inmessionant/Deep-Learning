## ########################################

####  调参经验

```
 - 学习率 3e-4
 - 数据归一化
 - L1 L2正则化 / weight decany
 - DropOut2d / DropPath / DropBlock[block size控制大小最好在7x7，；keep prob在整个训练过程中从1逐渐衰减到指定阈值
 - Batch Normalization / Group Normalization [每组channel为16]
 - BatchSize [大batchsize对小物体好，梯度累积]
 - OneCycleLR + SGD / Adam   (torch.optim.lr_scheduler.ReduceLROnPlateau)
 - Warm Up / Early stopping
 - 3x3卷积（有利于保持图像性质）
 - 卷积核权重初始化使用xavier（Tanh,Zé wéi'ěr）或者He normal（ReLU） 
 - cv2读取图片速度快比Pillow快
 - 加速训练pin_memory=true work_numbers=x(卡的数量x4) data.to(device,  no_blocking=True),设置为True后，数据直接保存在锁页内存中，后续直接传入cuda；否则需要先从虚拟内存中传入锁页内存中，再传入cuda
 - ReLU可使用inplace操作减少显存消耗
 - Focal Loss：对CE loss增加了一个调制系数来降低容易样本的权重值，使得训练过程更加关注困难样本
 - With Flooding:当training loss大于一个阈值时，进行正常的梯度下降；当training loss低于阈值时，会反过来进行梯度上升，让training loss保持在一个阈值附近，让模型持续进行"random walk"
 - Label Smoothing：使得原本的hard-target变为soft-target，让标签分布的熵增大,使网络优化更加平滑,通常用于减少训练的过拟合问题并进一步提高分类性能
```



#### 数据增强

```
 - Mix up / Cutout / Mosaic
 - Label Smoothing
 - 物体的复制粘贴（小物体）
 - 随机剪裁，翻转，缩放，亮度，色调，饱和度
 - 对普通数码照片进行归一化，可以简单的将0-255线性映射到0-1；而医学图像、遥感图像则不能简单的利用最小最大像元值归一化到0-1；
```

- 拼接增广指随机找几张图各取一部分或者缩小之后拼起来作为一幅图用，拼接出来的图有强烈的拼接痕迹；
- 抠洞指随机的将目标的一部分区域扣掉填充0值；

- **拼接、抠洞属于人为制造的伪显著区域，不符合实际情况，对工程应用来说没有意义，白白增加训练量；**
- **训练过程随机缩放也是没必要的，缩放之后的图像可能会导致特征图和输入图像映射错位；**



#### 深度学习挑战

- **应该更多地关注边缘情况（也就是异常值，或不寻常的情况），并思考这些异常值对预测可能意味着什么。**我们手上有大量的关于日常事务的数据，当前的技术很容易处理这些数据；而对于罕见的事件，我们得到的数据非常少，且目前的技术很难去处理这些数据；
- **我们人类拥有大量的不完全信息推理的技巧，也许可以克服生活中的长尾问题**。但对于目前流行的、更多依赖大数据而非推理的人工智能技术来说，长尾问题是一个非常严重的问题；
- 世上并不只有一种思维方式，因为思维并不是一个整体。相反，**思维是可以分为部分的，而且其不同部分以不同的方式运作**。例如，深度学习在识别物体方面做得相当不错，但在计划、阅读或语言理解方面做得差一些；
- **使用深度学习进行调试非常困难，因为没有人真正理解它是如何工作的，也没有人知道如何修复问题，**大众所知道的那种调试在经典编程环境中并不适用；



#### 有效阅读PyTorch源码

- **项目背景调研 + Paper**
- 阅读项目说明文档 + **README**
- 通过文件命名分析：**数据处理、数据加载**部分，通常命名xxx_dataloader.py等；**网络模型**构建部分，通常命名 resnet20.py model.py等；**训练部分**脚本，通常命名为train.py等；**测试部分**脚本，通常命名为test.py eval.py 等；**工具库**，通常命名为utils文件夹；
- **用IDE打开项目**，**找到项目运行的主入口**，阅读入口文件的逻辑，查看调用到了哪些 -  通过IDE的功能跳转到对应类或者函数进行继续阅读，配合代码注释进行分析。一开始可以泛读，大概了解整体流程，做一些代码注释，而后可以精读，找到文章的核心，反复理解核心实现；
- **3类BUG：**1.环境不兼容；深度学习框架；2.项目本身相关的BUG，这类BUG最好是在Issue区域进行查找，如果无法解决可以在issue部分详细描述自己的问题，等待项目库作者的解答；



#### 网络CheckList

- **从最简单的数据/模型开始，全流程走通：**
  - **模型简单**：解决一个深度学习任务，最好是先自己搭建一个最简单的神经网络；
  - **数据简单：** 一般来说少于**10个样本**做调试足够了，一定要**做过拟合测试** [如果你的模型无法在7、8个样本上过拟合，要么模型参数实在太少，要么有模型有BUG，要么数据有BUG，多选几个有代表性的输入数据有助于直接测试出非法数据格式；

- **选择合理的loss/评价指标，检查一下loss是否符合预期：**

  - **初始loss期望值和实际值误差是否过大：** 假如：CIFAR-10用Softmax Classifier进行10分类，那么一开始每个类别预测对的概率是0.1[随机预测]，Softmax loss使用的是negative log probability，所以正确的loss大概是：-ln（0.1）= 2.303左右；如果一开始loss不符合预期，那么可能是**模型初始化不均匀**或者**数据输入没有归一化；**

  - **多个loss相加，那这些loss的数值是否在同一个范围；**

  - **数据不均衡的时候尝试Focal Loss；**


- **网络中间输出、网络连接检查：**

  - 确认所有子网络的输入输出**Tensor对齐**，并确认全部都连接上了，可能有时候定义一个子网络，但放一边忘记连入主网络；

  - **梯度更新是否正确：** 如果某个参数没有梯度，那么是不是没有连入主网络； 有时候我们会通过参数名字来设置哪些梯度更新，哪些不更新，是否有误操作；

- **-时刻关注着模型参数：**

  - 所谓模型参数也就是一堆矩阵，如果这些数值中有些数值异常大/小，那么模型效果一般也会出现异常；


- **详细记录实验过程：**



## ########################################



## PyTorch



#### 默认梯度累积

- 机器显存小，可以变相增大batchsize；
- weight在不同模型之间交互时候有好处；（动手学习深度学习v2）

```py
accumulation_steps = batch_size // opt.batch_size

loss = loss / accumulation_steps
running_loss += loss.item()
loss.backward()

if ((i + 1) % accumulation_steps) == 0:
	optimizer.step()
	scheduler.step()
	optimizer.zero_grad()
```



#### PyTorch提速

- **图片解码**：cv2要比Pillow读取图片速度快
- 加速训练**pin_memory=true / work_numbers=x(卡的数量x4) / prefetch_factor=2 / data.to(device,  no_blocking=True)**
- **DALI库**在GPU端完成这部分**数据增强**，而不是**transform**做图片分类任务的数据增强
- OneCycleLR + SGD / AdamW
- `torch.nn.Conv2d(..., bias=False, ...)`
- DP & DDP 
- 不要频繁在CPU和GPU之间转移数据
- **混合精度训练：**`from torch.cuda import amp`使用`FP16`



#### Module & Functional

- **nn.Module**实现的layer是由class Layer(nn.Module)定义的特殊类，**会自动提取可学习参数nn.Parameter**；
- **nn.Functional**中的函数更像是**纯函数**，由def function(input)定义，一般只定义一个操作，其无法保存参数；



- **Module**只需定义 __init__和**forward**，而backward的计算由自动求导机制；
- **Function**需要定义三个方法：**init, forward, backward**（需要自己写求导公式） ；



- **对于激活函数和池化层，由于没有可学习参数，一般使用nn.functional完成，其他的有学习参数的部分则使用nn.Module；**
- 但是**Droupout**由于在训练和测试时操作不同，所以**建议使用nn.Module实现**，它能够通过**model.eval**加以区分；



#### Sequential & ModuleList

**区别：**

- **nn.Sequential内部实现了forward函数，而nn.ModuleList则没有实现内部forward函数**；
- **nn.Sequential可以使用OrderedDict对每层进行命名**;
- **nn.Sequential里面的模块按照顺序进行排列的**，所以必须确保前一个模块的输出和下一个模块的输入是一致的；而**nn.ModuleList 并没有定义一个网络，它只是将不同的模块储存在一起，这些模块之间并没有什么先后顺序可言**；
- **nn.ModuleList，它是一个储存不同 Module，并自动将每个 Module 的 Parameters 添加到网络之中的容器**；



**nn.Sequential**

- nn.Sequential里面的模块按照顺序进行排列的，所以必须确保前一个模块的输出大小和下一个模块的输入大小是一致的；
- nn.Sequential中可以使用OrderedDict来指定每个module的名字，而不是采用默认的命名方式；
- nn.Sequential内部实现了forward函数；

```python
from collections import OrderedDict

class net_seq(nn.Module):
    def __init__(self):
        super(net_seq, self).__init__()
        self.seq = nn.Sequential(OrderedDict([
                        ('conv1', nn.Conv2d(1,20,5)),
                         ('relu1', nn.ReLU()),
                          ('conv2', nn.Conv2d(20,64,5)),
                       ('relu2', nn.ReLU())
                       ]))
    def forward(self, x):
        return self.seq(x)
net_seq = net_seq()
```



**nn.ModuleList**

- **nn.ModuleList，它是一个储存不同 Module，并自动将每个 Module 的 Parameters 添加到网络之中的容器**：你可以把任意 nn.Module 的子类 (比如 nn.Conv2d, nn.Linear 之类的) 加到这个 list 里面，方法和 Python 自带的 list 一样，无非是 extend，append 等操作。但不同于一般的 list，加入到 nn.ModuleList 里面的 module 是会自动注册到整个网络上的，同时 module 的 parameters 也会自动添加到整个网络中，而使用 Python 的 list 添加的卷积层和它们的 parameters 并没有自动注册到我们的网络中；
- nn.ModuleList需要手动实现内部forward函数；

```python
class net_modlist(nn.Module):
    def __init__(self):
        super(net_modlist, self).__init__()
        self.modlist = nn.ModuleList([
                       nn.Conv2d(1, 20, 5),
                       nn.ReLU(),
                        nn.Conv2d(20, 64, 5),
                        nn.ReLU()
                        ])

    def forward(self, x):
        for m in self.modlist:
            x = m(x)
        return x

net_modlist = net_modlist()
```



#### DataLoader & Sampler & DataSet 

```python
class DataLoader(object):
	# DataLoader.next的源代码，__next__函数可以看到DataLoader对数据的读取其实就是用了for循环来遍历数据
    def __next__(self):
        if self.num_workers == 0:  
            indices = next(self.sample_iter)  # Sampler
            # collate_fn的作用就是将一个batch的数据进行合并操作。默认的collate_fn是将img和label分别合并成imgs和labels，所以如果你的__getitem__方法只是返回 img, label,那么你可以使用默认的collate_fn方法，但是如果你每次读取的数据有img, box, label等等，那么你就需要自定义collate_fn来将对应的数据合并成一个batch数据，这样方便后续的训练步骤
            batch = self.collate_fn([self.dataset[i] for i in indices]) # Dataset遍历数据，self.dataset[i]=(img, label)
            if self.pin_memory:
                batch = _utils.pin_memory.pin_memory_batch(batch)
            return batch
```



- **一般来说PyTorch中深度学习训练的流程是这样的： 1. 创建Dateset ；2. Dataset传递给DataLoader； 3. DataLoader迭代产生训练数据提供给模型；**
- 假设我们的数据是一组图像，每一张图像对应一个index，那么如果我们要读取数据就只需要对应的index即可，即代码中的`indices`，而选取index的方式有多种，有按顺序的，也有乱序的，所以这个工作需要`Sampler`完成，`DataLoader`和`Sampler`在这里产生关系；
- 我们已经拿到了indices，那么下一步我们只需要根据index对数据进行读取即可了，这时`Dataset`和`DataLoader`产生关系；

```
-------------------------------------
| DataLoader												|				
|																		|							
|			Sampler -----> Indices				|  													
|                       |						|	
|      DataSet -----> Data					|
|												|						|			
------------------------|------------                    
												|s						
                        Training
```



```python
class DataLoader(object):
  # DataLoader 的源代码
    def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None,
                 batch_sampler=None, num_workers=0, collate_fn=default_collate,
                 pin_memory=False, drop_last=False, timeout=0,
                 worker_init_fn=None)
```



DataLoader 的源代码初始化参数里有两种sampler：`sampler`和`batch_sampler`，都默认为`None`；前者的作用是生成一系列的index，而batch_sampler则是将sampler生成的indices打包分组，得到batch的index；

```python
>>>in : list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))
>>>out: [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]
```



Pytorch中已经实现的`Sampler`有如下几种：`SequentialSampler` 	`RandomSampler`	 `WeightedSampler` 	`SubsetRandomSampler`,需要注意的是DataLoader的部分初始化参数之间存在互斥关系，这个你可以通过阅读[源码](https://github.com/pytorch/pytorch/blob/0b868b19063645afed59d6d49aff1e43d1665b88/torch/utils/data/dataloader.py#L157-L182)更深地理解，这里只做总结：

- 如果你自定义了`batch_sampler`,那么`batch_size`, `shuffle`,`sampler`,`drop_last`这些参数都必须使用默认值；
- 如果你自定义了`sampler`，那么`shuffle`需要设置为`False`；
- 如果`sampler`和`batch_sampler`都为`None`,那么`batch_sampler`使用Pytorch已经实现好的`BatchSampler`,而`sampler`分两种情况：
  - 若`shuffle=True`,则`sampler=RandomSampler(dataset)`
  - 若`shuffle=False`,则`sampler=SequentialSampler(dataset)`




如何自定义Sampler和BatchSampler：查看源代码其实可以发现，所有采样器其实都继承自同一个父类，即`Sampler`,其代码定义如下：

```python
class Sampler(object):
    r"""Base class for all Samplers.
    Every Sampler subclass has to provide an :meth:`__iter__` method, providing a
    way to iterate over indices of dataset elements, and a :meth:`__len__` method
    that returns the length of the returned iterators.
    .. note:: The :meth:`__len__` method isn't strictly required by
              :class:`~torch.utils.data.DataLoader`, but is expected in any
              calculation involving the length of a :class:`~torch.utils.data.DataLoader`.
    """

    def __init__(self, data_source):
        pass

    def __iter__(self):
        raise NotImplementedError
		
    def __len__(self):
        return len(self.data_source)
```

- 所以你要做的就是定义好`__iter__(self)`函数，不过要注意的是该函数的返回值需要是可迭代的，例如`SequentialSampler`返回的是`iter(range(len(self.data_source)))`；
- 另外`BatchSampler`与其他Sampler的主要区别是它需要将Sampler作为参数进行打包，进而每次迭代返回以batch size为大小的index列表。也就是说在后面的读取数据过程中使用的都是batch sampler；



Dataset定义方式如下：

```python
class Dataset(object):
	def __init__(self):
		...
		
	def __getitem__(self, index):
		return ...
	
	def __len__(self):
		return ...
```

- 面三个方法是最基本的，其中`__getitem__`是最主要的方法，它规定了如何读取数据。但是它又不同于一般的方法，因为它是python built-in方法，其主要作用是能让该类可以像list一样通过索引值对数据进行访问。假如你定义好了一个dataset，那么你可以直接通过`dataset[0]`来访问第一个数据；



#### Model.Eval & Torch.No_Grad

- **两者都在Inference时候使用，但是作用不相同：**
  - model.eval() 负责改变batchnorm、dropout的工作方式，如在eval()模式下，dropout是不工作的；
  - torch.no_grad() 负责关掉梯度计算，节省eval的时间；
- **只进行Inference时，`model.eval()`是必须使用的，否则会影响结果准确性； 而`torch.no_grad()`并不是强制的，只影响运行效率；**



## ########################################









## ########################################
